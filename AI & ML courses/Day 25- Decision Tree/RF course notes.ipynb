{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f00651ab",
   "metadata": {},
   "source": [
    "Ensemble Learning\n",
    "\n",
    "- Ensemble learning combines multiple models to improve prediction accuracy, similar to averaging guesses from a large group rather than relying on a single expert.\n",
    "- It is effective even when individual models are only slightly better than random guessing.\n",
    "\n",
    "Bagging and Random Forests\n",
    "\n",
    "- Bagging, or bootstrap aggregating, involves training multiple models (base learners) on random subsets of the data to reduce correlation in errors.\n",
    "- Random forests are a specific type of ensemble that uses decision trees as base learners, each trained on bootstrapped data and a random subset of features.\n",
    "\n",
    "Advantages of Ensemble Learning\n",
    "\n",
    "- Ensemble methods reduce variance and bias, leading to more reliable predictions compared to individual models.\n",
    "- The diversity among base learners helps mitigate the risk of correlated errors, enhancing overall model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d283fce2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
